{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bbd4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sound_classification_dataset import SoundDS\n",
    "from sound_classification_model import AudioClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cec439c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "      <th>relative_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>/fold5/100032-3-0-0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>/fold5/100263-2-0-117.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>/fold5/100263-2-0-121.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>/fold5/100263-2-0-126.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>/fold5/100263-2-0-137.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class              relative_path  \n",
       "0          dog_bark    /fold5/100032-3-0-0.wav  \n",
       "1  children_playing  /fold5/100263-2-0-117.wav  \n",
       "2  children_playing  /fold5/100263-2-0-121.wav  \n",
       "3  children_playing  /fold5/100263-2-0-126.wav  \n",
       "4  children_playing  /fold5/100263-2-0-137.wav  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Prepare training data from Metadata file\n",
    "# ----------------------------\n",
    "\n",
    "data_path = 'UrbanSound8k'\n",
    "\n",
    "# Read metadata file\n",
    "metadata_file = data_path + '/UrbanSound8K.csv'\n",
    "df = pd.read_csv(metadata_file)\n",
    "df.head()\n",
    "\n",
    "# Construct file path by concatenating fold and file name\n",
    "df['relative_path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str)\n",
    "\n",
    "# Take relevant columns\n",
    "# df = df[['relative_path', 'classID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d7852eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61a13d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "myds = SoundDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48e08908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split of 80:20 between training and validation\n",
    "\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(myds[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n",
    "\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val_test = num_items - num_train\n",
    "train_ds, val_test_ds = random_split(myds, [num_train, num_val_test])\n",
    "num_val = round(num_val_test/2)\n",
    "num_test = num_val_test - num_val\n",
    "val_ds, test_ds = random_split(val_test_ds, [num_val, num_test])\n",
    "\n",
    "# # Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=128, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "624806fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6da670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model and put it on the GPU if available\n",
    "model = nn.DataParallel(AudioClassifier())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Check that it is on Cuda\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "054562e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = train_dl\n",
    "                data_size = len(train_ds)\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = val_dl\n",
    "                data_size = len(val_ds)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / data_size\n",
    "            epoch_acc = running_corrects.double() / data_size\n",
    "\n",
    "            print('{} - Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, 'model.pt')\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d7c53cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train - Loss: 2.2910 Acc: 0.1420\n",
      "val - Loss: 2.2332 Acc: 0.2050\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train - Loss: 2.2057 Acc: 0.2166\n",
      "val - Loss: 2.1659 Acc: 0.2703\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train - Loss: 2.1411 Acc: 0.2562\n",
      "val - Loss: 2.1126 Acc: 0.2818\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train - Loss: 2.0901 Acc: 0.2738\n",
      "val - Loss: 2.0709 Acc: 0.3013\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train - Loss: 2.0503 Acc: 0.2956\n",
      "val - Loss: 2.0232 Acc: 0.3196\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train - Loss: 2.0167 Acc: 0.3023\n",
      "val - Loss: 1.9971 Acc: 0.3276\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train - Loss: 1.9821 Acc: 0.3119\n",
      "val - Loss: 1.9719 Acc: 0.3265\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train - Loss: 1.9564 Acc: 0.3222\n",
      "val - Loss: 1.9475 Acc: 0.3597\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train - Loss: 1.9327 Acc: 0.3277\n",
      "val - Loss: 1.9233 Acc: 0.3471\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "train - Loss: 1.9108 Acc: 0.3352\n",
      "val - Loss: 1.9021 Acc: 0.3505\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "train - Loss: 1.8917 Acc: 0.3470\n",
      "val - Loss: 1.8866 Acc: 0.3608\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "train - Loss: 1.8698 Acc: 0.3534\n",
      "val - Loss: 1.8644 Acc: 0.3814\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "train - Loss: 1.8487 Acc: 0.3706\n",
      "val - Loss: 1.8424 Acc: 0.3975\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "train - Loss: 1.8290 Acc: 0.3790\n",
      "val - Loss: 1.8168 Acc: 0.4192\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "train - Loss: 1.8060 Acc: 0.3892\n",
      "val - Loss: 1.8004 Acc: 0.3986\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "train - Loss: 1.7877 Acc: 0.4038\n",
      "val - Loss: 1.7935 Acc: 0.3986\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "train - Loss: 1.7681 Acc: 0.4057\n",
      "val - Loss: 1.7682 Acc: 0.4181\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "train - Loss: 1.7526 Acc: 0.4165\n",
      "val - Loss: 1.7389 Acc: 0.4135\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "train - Loss: 1.7357 Acc: 0.4260\n",
      "val - Loss: 1.7269 Acc: 0.4296\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "train - Loss: 1.7197 Acc: 0.4237\n",
      "val - Loss: 1.6993 Acc: 0.4422\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "train - Loss: 1.6968 Acc: 0.4353\n",
      "val - Loss: 1.6994 Acc: 0.4330\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "train - Loss: 1.6793 Acc: 0.4410\n",
      "val - Loss: 1.6791 Acc: 0.4307\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "train - Loss: 1.6602 Acc: 0.4516\n",
      "val - Loss: 1.6529 Acc: 0.4410\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "train - Loss: 1.6429 Acc: 0.4599\n",
      "val - Loss: 1.6574 Acc: 0.4422\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "train - Loss: 1.6330 Acc: 0.4583\n",
      "val - Loss: 1.6224 Acc: 0.4593\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "train - Loss: 1.6207 Acc: 0.4624\n",
      "val - Loss: 1.6230 Acc: 0.4662\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "train - Loss: 1.6035 Acc: 0.4707\n",
      "val - Loss: 1.6062 Acc: 0.4593\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "train - Loss: 1.5846 Acc: 0.4771\n",
      "val - Loss: 1.5951 Acc: 0.4731\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "train - Loss: 1.5739 Acc: 0.4780\n",
      "val - Loss: 1.5751 Acc: 0.4800\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "train - Loss: 1.5627 Acc: 0.4865\n",
      "val - Loss: 1.5666 Acc: 0.4582\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "train - Loss: 1.5440 Acc: 0.4926\n",
      "val - Loss: 1.5534 Acc: 0.4800\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "train - Loss: 1.5374 Acc: 0.4868\n",
      "val - Loss: 1.5383 Acc: 0.4822\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "train - Loss: 1.5273 Acc: 0.4907\n",
      "val - Loss: 1.5332 Acc: 0.4834\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "train - Loss: 1.5106 Acc: 0.4991\n",
      "val - Loss: 1.5162 Acc: 0.4994\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "train - Loss: 1.4981 Acc: 0.5037\n",
      "val - Loss: 1.5041 Acc: 0.4971\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "train - Loss: 1.4873 Acc: 0.5044\n",
      "val - Loss: 1.4914 Acc: 0.5063\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "train - Loss: 1.4748 Acc: 0.5137\n",
      "val - Loss: 1.4907 Acc: 0.5029\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "train - Loss: 1.4613 Acc: 0.5162\n",
      "val - Loss: 1.4735 Acc: 0.5063\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "train - Loss: 1.4494 Acc: 0.5189\n",
      "val - Loss: 1.4670 Acc: 0.5132\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "train - Loss: 1.4376 Acc: 0.5196\n",
      "val - Loss: 1.4546 Acc: 0.5120\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "train - Loss: 1.4290 Acc: 0.5210\n",
      "val - Loss: 1.4454 Acc: 0.5052\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "train - Loss: 1.4180 Acc: 0.5269\n",
      "val - Loss: 1.4446 Acc: 0.5281\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "train - Loss: 1.4156 Acc: 0.5338\n",
      "val - Loss: 1.4353 Acc: 0.5189\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "train - Loss: 1.4109 Acc: 0.5273\n",
      "val - Loss: 1.4245 Acc: 0.5235\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "train - Loss: 1.3893 Acc: 0.5389\n",
      "val - Loss: 1.4030 Acc: 0.5372\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "train - Loss: 1.3891 Acc: 0.5348\n",
      "val - Loss: 1.3844 Acc: 0.5200\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "train - Loss: 1.3715 Acc: 0.5432\n",
      "val - Loss: 1.3840 Acc: 0.5372\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "train - Loss: 1.3622 Acc: 0.5470\n",
      "val - Loss: 1.3835 Acc: 0.5246\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "train - Loss: 1.3577 Acc: 0.5491\n",
      "val - Loss: 1.3754 Acc: 0.5258\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "train - Loss: 1.3454 Acc: 0.5488\n",
      "val - Loss: 1.3792 Acc: 0.5361\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "train - Loss: 1.3317 Acc: 0.5578\n",
      "val - Loss: 1.3405 Acc: 0.5521\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "train - Loss: 1.3338 Acc: 0.5502\n",
      "val - Loss: 1.3620 Acc: 0.5452\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "train - Loss: 1.3275 Acc: 0.5535\n",
      "val - Loss: 1.3551 Acc: 0.5315\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "train - Loss: 1.3173 Acc: 0.5607\n",
      "val - Loss: 1.3217 Acc: 0.5544\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "train - Loss: 1.3053 Acc: 0.5658\n",
      "val - Loss: 1.3273 Acc: 0.5510\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "train - Loss: 1.2969 Acc: 0.5693\n",
      "val - Loss: 1.3103 Acc: 0.5727\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "train - Loss: 1.2832 Acc: 0.5730\n",
      "val - Loss: 1.3037 Acc: 0.5682\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "train - Loss: 1.2853 Acc: 0.5660\n",
      "val - Loss: 1.3022 Acc: 0.5567\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "train - Loss: 1.2737 Acc: 0.5744\n",
      "val - Loss: 1.2990 Acc: 0.5578\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "train - Loss: 1.2592 Acc: 0.5817\n",
      "val - Loss: 1.2749 Acc: 0.5842\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "train - Loss: 1.2579 Acc: 0.5825\n",
      "val - Loss: 1.2597 Acc: 0.5865\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "train - Loss: 1.2527 Acc: 0.5842\n",
      "val - Loss: 1.2656 Acc: 0.5613\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "train - Loss: 1.2356 Acc: 0.5883\n",
      "val - Loss: 1.2684 Acc: 0.5762\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "train - Loss: 1.2349 Acc: 0.5908\n",
      "val - Loss: 1.2470 Acc: 0.5865\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "train - Loss: 1.2265 Acc: 0.5872\n",
      "val - Loss: 1.2386 Acc: 0.6014\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "train - Loss: 1.2229 Acc: 0.5902\n",
      "val - Loss: 1.2314 Acc: 0.5876\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "train - Loss: 1.2120 Acc: 0.5956\n",
      "val - Loss: 1.2144 Acc: 0.6025\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "train - Loss: 1.2013 Acc: 0.5973\n",
      "val - Loss: 1.2414 Acc: 0.5945\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "train - Loss: 1.2025 Acc: 0.5969\n",
      "val - Loss: 1.2057 Acc: 0.5945\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "train - Loss: 1.1942 Acc: 0.5991\n",
      "val - Loss: 1.2202 Acc: 0.5922\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "train - Loss: 1.1831 Acc: 0.6114\n",
      "val - Loss: 1.1969 Acc: 0.6117\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "train - Loss: 1.1685 Acc: 0.6111\n",
      "val - Loss: 1.2046 Acc: 0.6037\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "train - Loss: 1.1675 Acc: 0.6066\n",
      "val - Loss: 1.1743 Acc: 0.6117\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "train - Loss: 1.1587 Acc: 0.6129\n",
      "val - Loss: 1.1890 Acc: 0.6048\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "train - Loss: 1.1550 Acc: 0.6204\n",
      "val - Loss: 1.1847 Acc: 0.6048\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "train - Loss: 1.1597 Acc: 0.6122\n",
      "val - Loss: 1.1747 Acc: 0.6060\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "train - Loss: 1.1501 Acc: 0.6175\n",
      "val - Loss: 1.1614 Acc: 0.6369\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "train - Loss: 1.1323 Acc: 0.6202\n",
      "val - Loss: 1.1559 Acc: 0.6014\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "train - Loss: 1.1297 Acc: 0.6267\n",
      "val - Loss: 1.1519 Acc: 0.6186\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "train - Loss: 1.1181 Acc: 0.6270\n",
      "val - Loss: 1.1239 Acc: 0.6151\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "train - Loss: 1.1314 Acc: 0.6238\n",
      "val - Loss: 1.1405 Acc: 0.6208\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "train - Loss: 1.1230 Acc: 0.6247\n",
      "val - Loss: 1.1374 Acc: 0.6312\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "train - Loss: 1.1227 Acc: 0.6205\n",
      "val - Loss: 1.1286 Acc: 0.6289\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "train - Loss: 1.1101 Acc: 0.6267\n",
      "val - Loss: 1.1263 Acc: 0.6163\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "train - Loss: 1.0966 Acc: 0.6360\n",
      "val - Loss: 1.1150 Acc: 0.6323\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "train - Loss: 1.0891 Acc: 0.6419\n",
      "val - Loss: 1.1334 Acc: 0.6254\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "train - Loss: 1.0954 Acc: 0.6413\n",
      "val - Loss: 1.1009 Acc: 0.6346\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "train - Loss: 1.0887 Acc: 0.6356\n",
      "val - Loss: 1.1189 Acc: 0.6369\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "train - Loss: 1.0752 Acc: 0.6406\n",
      "val - Loss: 1.1020 Acc: 0.6403\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "train - Loss: 1.0840 Acc: 0.6350\n",
      "val - Loss: 1.0799 Acc: 0.6495\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "train - Loss: 1.0782 Acc: 0.6427\n",
      "val - Loss: 1.0810 Acc: 0.6529\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "train - Loss: 1.0723 Acc: 0.6383\n",
      "val - Loss: 1.0672 Acc: 0.6575\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Loss: 1.0457 Acc: 0.6489\n",
      "val - Loss: 1.0629 Acc: 0.6483\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "train - Loss: 1.0427 Acc: 0.6577\n",
      "val - Loss: 1.0706 Acc: 0.6586\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "train - Loss: 1.0529 Acc: 0.6504\n",
      "val - Loss: 1.0498 Acc: 0.6564\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "train - Loss: 1.0435 Acc: 0.6522\n",
      "val - Loss: 1.0583 Acc: 0.6541\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "train - Loss: 1.0365 Acc: 0.6600\n",
      "val - Loss: 1.0571 Acc: 0.6495\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "train - Loss: 1.0330 Acc: 0.6543\n",
      "val - Loss: 1.0745 Acc: 0.6518\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "train - Loss: 1.0356 Acc: 0.6539\n",
      "val - Loss: 1.0547 Acc: 0.6609\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "train - Loss: 1.0175 Acc: 0.6590\n",
      "val - Loss: 1.0571 Acc: 0.6392\n",
      "\n",
      "Training complete in 204m 6s\n",
      "Best val Acc: 0.660939\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                    steps_per_epoch=int(len(train_dl)),\n",
    "                                                    epochs=num_epochs,\n",
    "                                                    anneal_strategy='linear')\n",
    "    \n",
    "model_ft = train_model(model, criterion, optimizer, scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "# writer.flush()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00e3cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "def inference (model, test_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum()\n",
    "            print(correct_prediction)\n",
    "#             print(prediction.shape)\n",
    "            total_prediction += prediction.shape[0]\n",
    "#             print(total_prediction)\n",
    "        \n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3dfbc0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdcd9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11, device='cuda:0')\n",
      "tensor(26, device='cuda:0')\n",
      "tensor(41, device='cuda:0')\n",
      "tensor(52, device='cuda:0')\n",
      "tensor(67, device='cuda:0')\n",
      "tensor(79, device='cuda:0')\n",
      "tensor(91, device='cuda:0')\n",
      "Accuracy: 0.10, Total items: 873\n"
     ]
    }
   ],
   "source": [
    "# Run inference on trained model with the validation set load best model weights\n",
    "model_inf = nn.DataParallel(AudioClassifier())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_inf = model_inf.to(device)\n",
    "model_inf.load_state_dict(torch.load('model.pt'))\n",
    "model_inf.eval()\n",
    "inference(model_inf, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e67c6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the model predictions\n",
    "# Generic function to display predictions for a few images\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ef659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
